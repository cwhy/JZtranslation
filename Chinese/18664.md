![](http://www.swarma.org/swarma/ckfinder/userfiles/images/1428472209.jpg)  
  
2009年以来，深度学习在涉及到视觉, 听觉等人类和哺乳动物共有的较低级认知功能的任务中取得突破性进展（如图像识别, 语音识别）。在以DNN和CNN
为代表的主流深度学习之外，始于上世纪90年代的一些”另类“研究显示，在涉及到注意, 长/短时记忆, 语言, 策略学习等人类特有的高级认知功能的任务，深
度学习（主要是具有各种特定结构的深度神经网络）也有巨大潜力尚待开发，并从2014年开始得到学术界越来越多的重视。本次reading club从中选取若干有代表性的
工作，分几个专题进行研读讨论，这些研究为深度学习（更一般地，大数据驱动的复杂模型学习）的下一步发展指出了方向。  
规模：6～7次，核心成员10人以内  
  
Reinforcement learning & game playing  
Mnih, V., Kavukcuoglu, K., Silver, D., et al. Playing Atari with deep
reinforcement learning. NIPS Deep Learning Workshop, 2013.  
Mnih, V., Kavukcuoglu, K., Silver, D., et al. Human-level control through deep
reinforcement learning. Nature 518, 529–533, 2015.  
demo  
[http://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html](http://www
.douban.com/link2/?url=http%3A%2F%2Fcs.stanford.edu%2Fpeople%2Fkarpathy%2Fconv
netjs%2Fdemo%2Frldemo.html&link2key=51cba67192)  
Guo, X., Singh, S., Lee, H., et al. Deep learning for real-time Atari game
play using offline Monte-Carlo tree search planning. NIPS 2014.  
Chris J. Maddison, Aja Huang, Ilya Sutskever, David Silver. Move Evaluation in
Go Using Deep Convolutional Neural Networks. arXiv:1412.6564, 2014.  
Bakker, B. Reinforcement learning with Long Short-Term Memory. NIPS 2002.  
Koutnik J., Cuccu G., Schmidhuber J., Gomez F. Evolving Large-Scale Neural
Networks for Vision-Based Reinforcement Learning. In Proc. Genetic and
Evolutionary Computation Conference (GECCO), 2013.  
  
RNN / LSTM & sequence learning  
Hochreiter, S. and Schmidhuber, J. Long Short-Term Memory. Neural Computation,
9(8):1735–1780. 1997.  
Gers, A. and Schmidhuber, J. LSTM Recurrent Networks Learn Simple Context Free
and Context Sensitive Languages. IEEE Transactions on Neural Networks
12(6):1333-1340, 2001.  
Sutskever, Ilya, Vinyals, Oriol, and Le, Quoc. Sequence to sequence learning
with neural networks. NIPS 2014.  
Vinyals, Oriol, Toshev, Alexander, Bengio, Samy, and Erhan, Dumitru. Show and
tell: A neural image caption generator. arXiv:1411.4555, November 2014.  
  
Attention  
Mnih, V., Heess, N., Graves, A., et al. Recurrent models of visual attention.
NIPS 2014.  
Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. Multiple object
recognition with visual attention. arXiv preprint arXiv:1412.7755, 2014.  
Bahdanau, Dzmitry, Cho, Kyunghyun, and Bengio, Yoshua. Neural machine
translation by jointly learning to align and translate. arXiv:1409.0473,
September 2014.  
Gregor, K., Danihelka, I., Graves, A., Wierstra, D. DRAW: A Recurrent Neural
Network For Image Generation arXiv:1502.04623, 2015.  
  
Program learning, long-term memory and metalearning (learning to learn)  
Weston, Jason, Chopra, Sumit, and Bordes, Antoine. Memory networks.
arXiv:1410.3916, 2014.  
Graves, Alex, Wayne, Greg, and Danihelka, Ivo. Neural turing machines.
arXiv:1410.5401, 2014.  
Schmidhuber, J. An introspective network that can learn to run its own weight
change algorithm. ICANN 1993.  
Hochreiter, S., Younger, A. S., Conwell, P. R. Learning to Learn Using
Gradient Descent. ICANN 2001

