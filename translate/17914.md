![ ](../../UserFiles/Image/activity/darwin.jpg)

## Time:
06/05/2012
14:30

## Location:
3Club, Haidian District, Beijing

## Related Materials:
<http://www.kuaipan.com.cn/file/id_17495416136272783.htm>

## Live streaming:
<http://www.duobei.com/room/3044611067>
You can join the online event by visiting the link above. Playback will also be provided.

## Price:
RMB 15 (Including a drink for everyone)
[The charge is for the location rental, the activity itself is free]

## Main Speaker: 王钺


## Introduction:

Statistical learning reading club has been going on for 5 weeks, and we have learned the following:
* Classification and dimension reduction with Gaussion assmuption(QDA, LDA)
* Logistic Regression
* Sparsity
* Random Forest

Lots of interesting questions has been discussed, such as:
* Why sigmoid transform is used in logistic regression?
* Why use feature selection on regression and classification problems?
* Why better results are yielded by adding L1 constraint in linear regression?
* What method can we choose different problems and datasets?

We have part of the answers of the answers in some perspectives, but I believe that we will have a deeper understanding of the questions in the coming events.

## Contents:

On the sixth event of statistical learning reading club, Professor 王钺 from Tsinghua University will introduct to us statitical learning theory given limited sample data.

The contents include:
* The objective of statistical learning: risk minimization
* Methods to minimize risk: Empirical risk minimization and ???
* Application of statitical learning theory: SVM
